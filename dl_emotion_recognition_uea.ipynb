{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl-emotion-recognition-uea.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM4t7Uj9ZlYY6Yfe5p42MM0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charlessantarosa/dl-emotion-recognition-uea/blob/master/dl_emotion_recognition_uea.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPL-3IaZRw5Y"
      },
      "source": [
        "<div>\n",
        "    <h1><strong>Dataset: Natural Human Face Images for Emotion Recognition</strong></h1>\n",
        "    <h4>Link: <a href=\"https://www.kaggle.com/sudarshanvaidya/random-images-for-face-emotion-recognition\">https://www.kaggle.com/sudarshanvaidya/random-images-for-face-emotion-recognition</a></h4>\n",
        "    <div id=\"text\">\n",
        "        <p>\n",
        "São 5.500 + imagens com 8 categorias de emoções - raiva, desprezo, nojo, medo, felicidade, neutralidade, tristeza e surpresa. Todas as imagens contêm rosto humano em tons de cinza (ou esboço). Cada imagem tem uma escala de cinza de 224 x 224 pixels no formato PNG.</p>\n",
        "<p>As imagens são obtidas na Internet, onde estão disponíveis gratuitamente para download. Google, Unsplash, Flickr etc.</p>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRMe6CbdIRsT"
      },
      "source": [
        "## Configuração e Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAD6xRIaOb6o"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from urllib.request import urlopen\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.layers import Conv2D,MaxPooling2D,Flatten\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# from keras.utils import np_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "# from skimage import transform\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uujeRhQ8d87r"
      },
      "source": [
        "# Currenty Directory\n",
        "PATH_ROOT = !pwd\n",
        "PATH_ROOT\n",
        "\n",
        "# Global Vars\n",
        "DATASET_FILE = 'dl-emotion-recognition-uea.zip'\n",
        "DATASET_GOOGLE_DRIVER_ID = '1J0xMHoQqC6zBibSxukK-Gshfb5kK-P1y'\n",
        "DATASET_PATH = PATH_ROOT[0] + '/dataset/'\n",
        "DATASET_PREDICT = PATH_ROOT[0] + '/predict'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5_sXP_qdpZb"
      },
      "source": [
        "# Download Dataset.zip from GoogleDriver\n",
        "!gdown --id $DATASET_GOOGLE_DRIVER_ID\n",
        "!unzip -o $DATASET_FILE > /dev/null\n",
        "\n",
        "# !ls -la $DATASET_PATH\n",
        "# DATASET_PATH = '/home/charles/uea/deep-learning/datasets/dl-emotion-recognition-uea/'\n",
        "# !ls -la $DATASET_PATH\n",
        "\n",
        "print('\\nLista de pastas ....')\n",
        "!ls -la $DATASET_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMXRK0vrIbNb"
      },
      "source": [
        "## Processando Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zc-D7HASH_v"
      },
      "source": [
        "# Processing directory dataset\n",
        "\n",
        "total_images = 0\n",
        "classes = []\n",
        "for _dir in os.listdir(DATASET_PATH):\n",
        "    count = 0\n",
        "    for f in os.listdir(DATASET_PATH + _dir + \"/\"):\n",
        "        count += 1\n",
        "        total_images += 1\n",
        "        \n",
        "    classes.append(_dir)\n",
        "    print(f\"{_dir} => {count} imagens\")\n",
        "    \n",
        "print('\\n----------------------------------------------')    \n",
        "print(f\"\\nTotal: {total_images} imagens\")\n",
        "print('Total de classes: ', len(classes))\n",
        "print('Classes: ', classes)\n",
        "print('\\n----------------------------------------------')    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0MrUVk2SKjH"
      },
      "source": [
        "img_arr = np.empty(shape=(total_images, 48, 48, 3)) # Dimensão da imagem 48,48\n",
        "img_label = np.empty(shape=(total_images))\n",
        "label_to_text = {}\n",
        "\n",
        "i = 0\n",
        "e = 0\n",
        "for dir_ in os.listdir(DATASET_PATH):\n",
        "    if dir_ in classes:\n",
        "        label_to_text[e] = dir_\n",
        "        for f in os.listdir(DATASET_PATH + dir_ + \"/\"):\n",
        "\n",
        "            image = cv2.imread(DATASET_PATH + dir_ + \"/\" + f)\n",
        "            img_arr[i] = cv2.resize(image, (48, 48))\n",
        "\n",
        "\n",
        "            img_label[i] = e\n",
        "\n",
        "            i += 1\n",
        "        print(f\"Imagens {dir_} carregadas!!!\")\n",
        "        e += 1\n",
        "\n",
        "img_arr.shape, img_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfv88B4GSNAd"
      },
      "source": [
        "img_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TkEZdQmSPAd"
      },
      "source": [
        "# Classes\n",
        "\n",
        "label_to_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXfwlP1BIi-D"
      },
      "source": [
        "## Visualização dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPFdNmGpSRHv"
      },
      "source": [
        "# Visualização Randômica de 2 imagens por classe.\n",
        "\n",
        "fig = pyplot.figure(1, (8, 8))\n",
        "\n",
        "idx = 0\n",
        "for k in label_to_text:\n",
        "    \n",
        "    sample_indices = np.random.choice(np.where(img_label==k)[0], size=2, replace=False)\n",
        "    sample_images = img_arr[sample_indices]\n",
        "    \n",
        "    for img in sample_images:\n",
        "        idx += 1\n",
        "        ax = pyplot.subplot(4, 4, idx)\n",
        "        ax.imshow(img[:,:,0], cmap='gray')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.set_title(label_to_text[k])\n",
        "        pyplot.tight_layout()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZRZbS4jaR8Z"
      },
      "source": [
        "## Trainamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5UTYqtEcJQv"
      },
      "source": [
        "img_arr = img_arr.reshape(len(img_arr), 48, 48, 3)\n",
        "data = np.array(img_arr, dtype=\"float32\") / 255.0\n",
        "# test_data = np.array(test_data, dtype=\"float\") / 255.0\n",
        "\n",
        "le = LabelEncoder()\n",
        "train_label = le.fit_transform(img_label)\n",
        "train_label = to_categorical(train_label)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, train_label, test_size=0.1, random_state=42)\n",
        "print(X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao4mSR0OhaJv"
      },
      "source": [
        "model = Sequential()\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "model.add(Conv2D(500, kernel_size=(3,3), input_shape=(48, 48, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Predição\n",
        "model.add(Dense(num_classes, activation='softmax', name='predict'))\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i62rvu0iX11"
      },
      "source": [
        "# Fit\n",
        "history = model.fit(x=X_train, y=y_train,  epochs=15, verbose=1, validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO_KTNZOm4UK"
      },
      "source": [
        "# Acurária\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test Loss: %.6f\" % (scores[0]))\n",
        "print(\"Test Acurária: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT5Ydf6SqfjI"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test Loss: %.6f\" % (scores[0]))\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeoP4FgXpaax"
      },
      "source": [
        "ig, ax = plt.subplots(1,2, figsize=(16,8))\n",
        "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuZW8AZQmqVd"
      },
      "source": [
        "## Validaçao do modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVy11D0DccOy"
      },
      "source": [
        "!rm -rf $DATASET_PREDICT\n",
        "!git clone https://github.com/charlessantarosa/dl-emotion-recognition-uea.git $DATASET_PREDICT\n",
        "!ls -la $DATASET_PREDICT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnMokvrcevTW"
      },
      "source": [
        "def getImage(filename):\n",
        "  \n",
        "  img_path = DATASET_PREDICT + '/' + filename\n",
        "  image_display = Image.open(img_path)\n",
        "  image_size= (48,48)\n",
        "\n",
        "  img = keras.preprocessing.image.load_img(img_path, target_size=image_size)\n",
        "  np_image = keras.preprocessing.image.img_to_array(img)\n",
        "  np_image = tf.expand_dims(np_image, 0)  # Create batch axis\n",
        "\n",
        "  return np_image, image_display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcKPICRErSoT"
      },
      "source": [
        "print('\\nEmotions Recognition ...\\n')\n",
        "label_to_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpTm7XuXDpcJ"
      },
      "source": [
        "img_pred, image = getImage('e1.png')\n",
        "plt.imshow(image)\n",
        "\n",
        "predictions = model.predict(img_pred)\n",
        "score = predictions.argmax()\n",
        "\n",
        "print(f'Resultado: [{score}] => ' + label_to_text[score])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Toy1ek3b-3iv"
      },
      "source": [
        "img_pred, image = getImage('e2.png')\n",
        "plt.imshow(image)\n",
        "\n",
        "predictions = model.predict(img_pred)\n",
        "score = predictions.argmax()\n",
        "\n",
        "print(f'Resultado: [{score}] => ' + label_to_text[score])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psxt0qKa_moq"
      },
      "source": [
        "img_pred, image = getImage('e3.png')\n",
        "plt.imshow(image)\n",
        "\n",
        "predictions = model.predict(img_pred)\n",
        "score = predictions.argmax()\n",
        "\n",
        "print(f'Resultado: [{score}] => ' + label_to_text[score])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onx_Weh7I2Zn"
      },
      "source": [
        "img_pred, image = getImage('e4.png')\n",
        "plt.imshow(image)\n",
        "\n",
        "predictions = model.predict(img_pred)\n",
        "score = predictions.argmax()\n",
        "\n",
        "print(f'Resultado: [{score}] => ' + label_to_text[score])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOJc8uCNJFSa"
      },
      "source": [
        "img_pred, image = getImage('e5.png')\n",
        "plt.imshow(image)\n",
        "\n",
        "predictions = model.predict(img_pred)\n",
        "score = predictions.argmax()\n",
        "\n",
        "print(f'Resultado: [{score}] => ' + label_to_text[score])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkxaMtTAJKwD"
      },
      "source": [
        "img_pred, image = getImage('e6.png')\n",
        "plt.imshow(image)\n",
        "\n",
        "predictions = model.predict(img_pred)\n",
        "score = predictions.argmax()\n",
        "\n",
        "print(f'Resultado: [{score}] => ' + label_to_text[score])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}