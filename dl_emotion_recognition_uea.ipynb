{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl-emotion-recognition-uea.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMQthzsvIfnjzLONUOr+yEu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charlessantarosa/dl-emotion-recognition-uea/blob/master/dl_emotion_recognition_uea.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPL-3IaZRw5Y"
      },
      "source": [
        "<div>\n",
        "    <h1><strong>Dataset: Natural Human Face Images for Emotion Recognition</strong></h1>\n",
        "    <h4>Link: <a href=\"https://www.kaggle.com/sudarshanvaidya/random-images-for-face-emotion-recognition\">sa</a></h4>\n",
        "    <div id=\"text\">\n",
        "        <p>\n",
        "São 5.500 + imagens com 8 categorias de emoções - raiva, desprezo, nojo, medo, felicidade, neutralidade, tristeza e surpresa. Todas as imagens contêm rosto humano em tons de cinza (ou esboço). Cada imagem tem uma escala de cinza de 224 x 224 pixels no formato PNG.</p>\n",
        "<p>As imagens são obtidas na Internet, onde estão disponíveis gratuitamente para download. Google, Unsplash, Flickr etc.</p>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAD6xRIaOb6o"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, GlobalAvgPool2D, GlobalMaxPool2D\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5_sXP_qdpZb"
      },
      "source": [
        "# Currenty Directory\n",
        "PATH_ROOT = !pwd\n",
        "PATH_ROOT\n",
        "\n",
        "# Global Vars\n",
        "DATASET_FILE = 'dl-emotion-recognition-uea.zip'\n",
        "DATASET_GOOGLE_DRIVER_ID = '1J0xMHoQqC6zBibSxukK-Gshfb5kK-P1y'\n",
        "DATASET_PATH = PATH_ROOT[0] + '/dataset/'\n",
        "\n",
        "# Download Dataset.zip from GoogleDriver\n",
        "!gdown --id $DATASET_GOOGLE_DRIVER_ID\n",
        "!unzip -o $DATASET_FILE\n",
        "\n",
        "# !ls -la $DATASET_PATH\n",
        "\n",
        "# DATASET_PATH = '/home/charles/uea/deep-learning/datasets/dl-emotion-recognition-uea/'\n",
        "# !ls -la $DATASET_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMc8z-nnAcs_"
      },
      "source": [
        "!ls -la $DATASET_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zc-D7HASH_v"
      },
      "source": [
        "# Processing directory dataset\n",
        "\n",
        "total_images = 0\n",
        "classes = []\n",
        "for _dir in os.listdir(DATASET_PATH):\n",
        "    count = 0\n",
        "    for f in os.listdir(DATASET_PATH + _dir + \"/\"):\n",
        "        count += 1\n",
        "        total_images += 1\n",
        "        \n",
        "    classes.append(_dir)\n",
        "    print(f\"{_dir} => {count} imagens\")\n",
        "    \n",
        "print('\\n----------------------------------------------')    \n",
        "print(f\"\\nTotal: {total_images} imagens\")\n",
        "print('Total de classes: ', len(classes))\n",
        "print('Classes: ', classes)\n",
        "print('\\n----------------------------------------------')    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0MrUVk2SKjH"
      },
      "source": [
        "img_arr = np.empty(shape=(total_images, 224, 224, 3))\n",
        "img_label = np.empty(shape=(total_images))\n",
        "label_to_text = {}\n",
        "\n",
        "i = 0\n",
        "e = 0\n",
        "for dir_ in os.listdir(DATASET_PATH):\n",
        "    if dir_ in classes:\n",
        "        label_to_text[e] = dir_\n",
        "        for f in os.listdir(DATASET_PATH + dir_ + \"/\"):\n",
        "            img_arr[i] = cv2.imread(DATASET_PATH + dir_ + \"/\" + f)\n",
        "            img_label[i] = e\n",
        "            i += 1\n",
        "        print(f\"loaded all {dir_} images to numpy arrays\")\n",
        "        e += 1\n",
        "\n",
        "img_arr.shape, img_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfv88B4GSNAd"
      },
      "source": [
        "print(img_arr[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TkEZdQmSPAd"
      },
      "source": [
        "# Classes\n",
        "\n",
        "label_to_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPFdNmGpSRHv"
      },
      "source": [
        "# Visualização Randômica de 2 imagens por classe.\n",
        "\n",
        "fig = pyplot.figure(1, (8, 8))\n",
        "\n",
        "idx = 0\n",
        "for k in label_to_text:\n",
        "    \n",
        "    sample_indices = np.random.choice(np.where(img_label==k)[0], size=2, replace=False)\n",
        "    sample_images = img_arr[sample_indices]\n",
        "    \n",
        "    for img in sample_images:\n",
        "        idx += 1\n",
        "        ax = pyplot.subplot(4, 4, idx)\n",
        "        ax.imshow(img[:,:,0], cmap='gray')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.set_title(label_to_text[k])\n",
        "        pyplot.tight_layout()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARafJBtySTub"
      },
      "source": [
        "# X, Y = np.array(img_arr) / 255.0, np.array(img_label)\n",
        "X = np.array(img_arr) / 255\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt2dNRkg2aOF"
      },
      "source": [
        "Y = np.array(img_label)\n",
        "Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5N_6XSeSYor"
      },
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK-AwPeQSao-"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a-M0e3KEoAt"
      },
      "source": [
        "# Converter para valores multiclasse. Valores convertidos para uma matriz que vão categorizar os dados\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHfwlD5-FBP9"
      },
      "source": [
        "y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCjXlB26GYGo"
      },
      "source": [
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C66qeGtRHLVD"
      },
      "source": [
        "# Model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(30, (4, 4), input_shape=(6, 224, 244), activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax', name='Predict'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1ytWQonVEOp"
      },
      "source": [
        "# Train\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=7, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}